{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f33d2ac",
   "metadata": {},
   "source": [
    "\n",
    "# 20 Newsgroups — End‑to‑End Experiments with MLflow\n",
    "\n",
    "This notebook contains two independent workflows on the 20 Newsgroups dataset:\n",
    "\n",
    "1. **PyCaret + MLflow** with TF‑IDF → SVD features, automated model comparison/tuning, and artifact logging.\n",
    "2. **PyTorch MLP + MLflow** with TF‑IDF → SVD features, manual training loop and logging.\n",
    "\n",
    "> **Notes (Windows users):**\n",
    "> - Keep artifact paths short if you run a local MLflow server to avoid long‑path issues.\n",
    "> - If PyCaret/MLflow versions in your environment are incompatible, pin `mlflow==2.12.1` and use a recent PyCaret (e.g., 3.3.x). \n",
    "> - If PyCaret raises a `sklearn` private API error, uncomment the small shim in the PyCaret section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25480369",
   "metadata": {},
   "source": [
    "## 1) PyCaret + MLflow (TF‑IDF → SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b13130f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment ready: 20NG-PyCaret\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, json\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "import mlflow\n",
    "\n",
    "EXPERIMENT_NAME = \"20NG-PyCaret\"\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "ART_DIR = Path(\"artifacts\"); ART_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def close_all_runs():\n",
    "    while mlflow.active_run() is not None:\n",
    "        mlflow.end_run()\n",
    "\n",
    "close_all_runs()\n",
    "print(\"Experiment ready:\", EXPERIMENT_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abd3b394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15076, 3770, 150)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset = fetch_20newsgroups(subset='all')\n",
    "X, y = dataset.data, dataset.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=30000, sublinear_tf=True)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf  = tfidf.transform(X_test)\n",
    "\n",
    "svd = TruncatedSVD(n_components=150, random_state=42)\n",
    "X_train_svd = svd.fit_transform(X_train_tfidf)\n",
    "X_test_svd  = svd.transform(X_test_tfidf)\n",
    "\n",
    "joblib.dump(tfidf, ART_DIR / \"tfidf_20ng.joblib\")\n",
    "joblib.dump(svd,   ART_DIR / \"svd_20ng_150.joblib\")\n",
    "\n",
    "cols = [f\"svd_{i}\" for i in range(X_train_svd.shape[1])]\n",
    "train_df = pd.DataFrame(X_train_svd, columns=cols); train_df[\"label\"] = y_train\n",
    "test_df  = pd.DataFrame(X_test_svd,  columns=cols); test_df[\"label\"]  = y_test\n",
    "\n",
    "len(train_df), len(test_df), train_df.shape[1]-1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "754f6723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf', 'nb', 'lightgbm', 'xgboost', 'ridge', 'lr']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def _filter_available(models):\n",
    "    avail = set(models)\n",
    "    try:\n",
    "        import lightgbm  \n",
    "    except Exception:\n",
    "        avail.discard(\"lightgbm\")\n",
    "    try:\n",
    "        import xgboost  \n",
    "    except Exception:\n",
    "        avail.discard(\"xgboost\")\n",
    "    return list(avail)\n",
    "\n",
    "include_models = _filter_available([\"lr\", \"ridge\", \"nb\", \"rf\", \"lightgbm\", \"xgboost\"])\n",
    "include_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67ca9e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Description            Value\n",
      "0                    Session id               42\n",
      "1                        Target            label\n",
      "2                   Target type       Multiclass\n",
      "3           Original data shape     (15076, 151)\n",
      "4        Transformed data shape     (15076, 151)\n",
      "5   Transformed train set shape     (10553, 151)\n",
      "6    Transformed test set shape      (4523, 151)\n",
      "7              Numeric features              150\n",
      "8                    Preprocess             True\n",
      "9               Imputation type           simple\n",
      "10           Numeric imputation             mean\n",
      "11       Categorical imputation             mode\n",
      "12               Fold Generator  StratifiedKFold\n",
      "13                  Fold Number                3\n",
      "14                     CPU Jobs               -1\n",
      "15                      Use GPU            False\n",
      "16               Log Experiment     MlflowLogger\n",
      "17              Experiment Name     20NG-PyCaret\n",
      "18                          USI             d0d9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Model  Accuracy     AUC  Recall   Prec.      F1  \\\n",
      "lr             Logistic Regression    0.8199  0.0000  0.8199  0.8230  0.8156   \n",
      "ridge             Ridge Classifier    0.8184  0.0000  0.8184  0.8182  0.8119   \n",
      "xgboost  Extreme Gradient Boosting    0.8082  0.9842  0.8082  0.8087  0.8076   \n",
      "rf        Random Forest Classifier    0.7916  0.9760  0.7916  0.7951  0.7901   \n",
      "nb                     Naive Bayes    0.6751  0.9435  0.6751  0.7001  0.6802   \n",
      "\n",
      "          Kappa     MCC  TT (Sec)  \n",
      "lr       0.8102  0.8106    0.1400  \n",
      "ridge    0.8087  0.8091    0.6267  \n",
      "xgboost  0.7980  0.7981   10.4333  \n",
      "rf       0.7805  0.7807    1.8100  \n",
      "nb       0.6577  0.6587    0.7000  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "      <th>TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.8199</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8199</td>\n",
       "      <td>0.8230</td>\n",
       "      <td>0.8156</td>\n",
       "      <td>0.8102</td>\n",
       "      <td>0.8106</td>\n",
       "      <td>0.1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge</th>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>0.8184</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8184</td>\n",
       "      <td>0.8182</td>\n",
       "      <td>0.8119</td>\n",
       "      <td>0.8087</td>\n",
       "      <td>0.8091</td>\n",
       "      <td>0.6267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>Extreme Gradient Boosting</td>\n",
       "      <td>0.8082</td>\n",
       "      <td>0.9842</td>\n",
       "      <td>0.8082</td>\n",
       "      <td>0.8087</td>\n",
       "      <td>0.8076</td>\n",
       "      <td>0.7980</td>\n",
       "      <td>0.7981</td>\n",
       "      <td>10.4333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.7916</td>\n",
       "      <td>0.9760</td>\n",
       "      <td>0.7916</td>\n",
       "      <td>0.7951</td>\n",
       "      <td>0.7901</td>\n",
       "      <td>0.7805</td>\n",
       "      <td>0.7807</td>\n",
       "      <td>1.8100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.6751</td>\n",
       "      <td>0.9435</td>\n",
       "      <td>0.6751</td>\n",
       "      <td>0.7001</td>\n",
       "      <td>0.6802</td>\n",
       "      <td>0.6577</td>\n",
       "      <td>0.6587</td>\n",
       "      <td>0.7000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model  Accuracy     AUC  Recall   Prec.      F1  \\\n",
       "lr             Logistic Regression    0.8199  0.0000  0.8199  0.8230  0.8156   \n",
       "ridge             Ridge Classifier    0.8184  0.0000  0.8184  0.8182  0.8119   \n",
       "xgboost  Extreme Gradient Boosting    0.8082  0.9842  0.8082  0.8087  0.8076   \n",
       "rf        Random Forest Classifier    0.7916  0.9760  0.7916  0.7951  0.7901   \n",
       "nb                     Naive Bayes    0.6751  0.9435  0.6751  0.7001  0.6802   \n",
       "\n",
       "          Kappa     MCC  TT (Sec)  \n",
       "lr       0.8102  0.8106    0.1400  \n",
       "ridge    0.8087  0.8091    0.6267  \n",
       "xgboost  0.7980  0.7981   10.4333  \n",
       "rf       0.7805  0.7807    1.8100  \n",
       "nb       0.6577  0.6587    0.7000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from pycaret.classification import (\n",
    "    setup, compare_models, tune_model, finalize_model, predict_model, save_model, pull\n",
    ")\n",
    "\n",
    "clf = setup(\n",
    "    data=train_df,\n",
    "    target=\"label\",\n",
    "    session_id=42,\n",
    "    fold=3,\n",
    "    html=False,\n",
    "    log_experiment=True,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    experiment_custom_tags={\"dataset\":\"20newsgroups\",\"features\":\"tfidf+svd\"},\n",
    "    log_plots=True,\n",
    "    log_profile=False,\n",
    "    log_data=False,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "best = compare_models(\n",
    "    include=include_models,\n",
    "    n_select=1,\n",
    "    turbo=False,\n",
    "    budget_time=300\n",
    ")\n",
    "\n",
    "leaderboard = pull()\n",
    "lb_path = ART_DIR / \"leaderboard.csv\"\n",
    "leaderboard.to_csv(lb_path, index=False)\n",
    "leaderboard.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c40e20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Accuracy  AUC  Recall   Prec.      F1   Kappa     MCC\n",
      "Fold                                                       \n",
      "0       0.8368  0.0  0.8368  0.8399  0.8376  0.8281  0.8282\n",
      "1       0.8474  0.0  0.8474  0.8484  0.8476  0.8392  0.8393\n",
      "2       0.8388  0.0  0.8388  0.8438  0.8400  0.8302  0.8304\n",
      "Mean    0.8410  0.0  0.8410  0.8440  0.8417  0.8325  0.8326\n",
      "Std     0.0046  0.0  0.0046  0.0035  0.0043  0.0048  0.0048\n",
      "                 Model  Accuracy     AUC  Recall   Prec.      F1   Kappa  \\\n",
      "0  Logistic Regression    0.8674  0.9919  0.8674  0.8681  0.8674  0.8603   \n",
      "\n",
      "      MCC  \n",
      "0  0.8604  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>svd_0</th>\n",
       "      <th>svd_1</th>\n",
       "      <th>svd_2</th>\n",
       "      <th>svd_3</th>\n",
       "      <th>svd_4</th>\n",
       "      <th>svd_5</th>\n",
       "      <th>svd_6</th>\n",
       "      <th>svd_7</th>\n",
       "      <th>svd_8</th>\n",
       "      <th>svd_9</th>\n",
       "      <th>...</th>\n",
       "      <th>svd_143</th>\n",
       "      <th>svd_144</th>\n",
       "      <th>svd_145</th>\n",
       "      <th>svd_146</th>\n",
       "      <th>svd_147</th>\n",
       "      <th>svd_148</th>\n",
       "      <th>svd_149</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction_label</th>\n",
       "      <th>prediction_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.051136</td>\n",
       "      <td>-0.044209</td>\n",
       "      <td>0.013876</td>\n",
       "      <td>-0.014207</td>\n",
       "      <td>0.010195</td>\n",
       "      <td>0.018256</td>\n",
       "      <td>0.002139</td>\n",
       "      <td>0.019463</td>\n",
       "      <td>0.004180</td>\n",
       "      <td>-0.007518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013087</td>\n",
       "      <td>0.012224</td>\n",
       "      <td>0.010218</td>\n",
       "      <td>0.019890</td>\n",
       "      <td>0.007670</td>\n",
       "      <td>0.009534</td>\n",
       "      <td>0.016458</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.148950</td>\n",
       "      <td>-0.022029</td>\n",
       "      <td>-0.051318</td>\n",
       "      <td>-0.045028</td>\n",
       "      <td>0.060533</td>\n",
       "      <td>-0.028787</td>\n",
       "      <td>0.058711</td>\n",
       "      <td>0.029263</td>\n",
       "      <td>-0.000823</td>\n",
       "      <td>-0.011804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003848</td>\n",
       "      <td>0.037028</td>\n",
       "      <td>0.018487</td>\n",
       "      <td>-0.008069</td>\n",
       "      <td>-0.015455</td>\n",
       "      <td>-0.013960</td>\n",
       "      <td>0.015685</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0.2750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.127395</td>\n",
       "      <td>-0.002190</td>\n",
       "      <td>0.041384</td>\n",
       "      <td>-0.001889</td>\n",
       "      <td>-0.019644</td>\n",
       "      <td>-0.022073</td>\n",
       "      <td>-0.007373</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>0.006122</td>\n",
       "      <td>-0.001303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018730</td>\n",
       "      <td>0.022513</td>\n",
       "      <td>0.012194</td>\n",
       "      <td>-0.015511</td>\n",
       "      <td>-0.039467</td>\n",
       "      <td>0.005832</td>\n",
       "      <td>0.024015</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.154591</td>\n",
       "      <td>0.003464</td>\n",
       "      <td>0.014266</td>\n",
       "      <td>0.020361</td>\n",
       "      <td>-0.034787</td>\n",
       "      <td>-0.003228</td>\n",
       "      <td>-0.012234</td>\n",
       "      <td>-0.059677</td>\n",
       "      <td>0.039645</td>\n",
       "      <td>0.025397</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027196</td>\n",
       "      <td>0.036850</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.008930</td>\n",
       "      <td>-0.060703</td>\n",
       "      <td>-0.016321</td>\n",
       "      <td>-0.039191</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.3642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.155006</td>\n",
       "      <td>0.042561</td>\n",
       "      <td>-0.049434</td>\n",
       "      <td>-0.031397</td>\n",
       "      <td>0.037215</td>\n",
       "      <td>0.020427</td>\n",
       "      <td>0.065599</td>\n",
       "      <td>0.019820</td>\n",
       "      <td>-0.005767</td>\n",
       "      <td>-0.027879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004671</td>\n",
       "      <td>0.023195</td>\n",
       "      <td>0.014267</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>-0.002615</td>\n",
       "      <td>-0.031948</td>\n",
       "      <td>-0.003028</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0.7586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      svd_0     svd_1     svd_2     svd_3     svd_4     svd_5     svd_6  \\\n",
       "0  0.051136 -0.044209  0.013876 -0.014207  0.010195  0.018256  0.002139   \n",
       "1  0.148950 -0.022029 -0.051318 -0.045028  0.060533 -0.028787  0.058711   \n",
       "2  0.127395 -0.002190  0.041384 -0.001889 -0.019644 -0.022073 -0.007373   \n",
       "3  0.154591  0.003464  0.014266  0.020361 -0.034787 -0.003228 -0.012234   \n",
       "4  0.155006  0.042561 -0.049434 -0.031397  0.037215  0.020427  0.065599   \n",
       "\n",
       "      svd_7     svd_8     svd_9  ...   svd_143   svd_144   svd_145   svd_146  \\\n",
       "0  0.019463  0.004180 -0.007518  ...  0.013087  0.012224  0.010218  0.019890   \n",
       "1  0.029263 -0.000823 -0.011804  ...  0.003848  0.037028  0.018487 -0.008069   \n",
       "2  0.001285  0.006122 -0.001303  ...  0.018730  0.022513  0.012194 -0.015511   \n",
       "3 -0.059677  0.039645  0.025397  ... -0.027196  0.036850  0.000714  0.008930   \n",
       "4  0.019820 -0.005767 -0.027879  ...  0.004671  0.023195  0.014267  0.001620   \n",
       "\n",
       "    svd_147   svd_148   svd_149  label  prediction_label  prediction_score  \n",
       "0  0.007670  0.009534  0.016458      1                 1            0.6053  \n",
       "1 -0.015455 -0.013960  0.015685     19                19            0.2750  \n",
       "2 -0.039467  0.005832  0.024015      5                 5            0.4727  \n",
       "3 -0.060703 -0.016321 -0.039191      7                 7            0.3642  \n",
       "4 -0.002615 -0.031948 -0.003028     17                17            0.7586  \n",
       "\n",
       "[5 rows x 153 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "best_tuned = tune_model(best, optimize=\"Accuracy\", n_iter=20, choose_better=True)\n",
    "final_model = finalize_model(best_tuned)\n",
    "\n",
    "test_preds = predict_model(final_model, data=test_df)\n",
    "pred_path = ART_DIR / \"test_predictions_head.csv\"\n",
    "test_preds.head(50).to_csv(pred_path, index=False)\n",
    "test_preds.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d868a1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n",
      "PyCaret section completed. Check MLflow experiment: 20NG-PyCaret\n"
     ]
    }
   ],
   "source": [
    "\n",
    "save_model(final_model, str(ART_DIR / \"best_20ng_pycaret\"))\n",
    "\n",
    "close_all_runs() \n",
    "\n",
    "with mlflow.start_run(run_name=\"extra_artifacts_attach\"):\n",
    "    mlflow.log_params({\n",
    "        \"vectorizer\":\"tfidf\",\n",
    "        \"tfidf_stop_words\":\"english\",\n",
    "        \"tfidf_max_features\":30000,\n",
    "        \"tfidf_sublinear_tf\":True,\n",
    "        \"svd_n_components\":150,\n",
    "        \"test_size\":0.2,\n",
    "        \"random_state\":42\n",
    "    })\n",
    "    mlflow.log_artifact(str(ART_DIR / \"tfidf_20ng.joblib\"), artifact_path=\"preprocessing\")\n",
    "    mlflow.log_artifact(str(ART_DIR / \"svd_20ng_150.joblib\"), artifact_path=\"preprocessing\")\n",
    "    mlflow.log_artifact(str(ART_DIR / \"leaderboard.csv\"), artifact_path=\"reports\")\n",
    "    mlflow.log_artifact(str(ART_DIR / \"test_predictions_head.csv\"), artifact_path=\"reports\")\n",
    "    mlflow.log_artifact(str(ART_DIR / \"best_20ng_pycaret.pkl\"), artifact_path=\"model_pickles\")\n",
    "\n",
    "print(\"PyCaret section completed. Check MLflow experiment:\", EXPERIMENT_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c6910d",
   "metadata": {},
   "source": [
    "## 2) PyTorch MLP + MLflow (TF‑IDF → SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b20f850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | test acc=0.6061\n",
      "Epoch 02 | test acc=0.8003\n",
      "Epoch 03 | test acc=0.8361\n",
      "Epoch 04 | test acc=0.8467\n",
      "Epoch 05 | test acc=0.8560\n",
      "Epoch 06 | test acc=0.8578\n",
      "Epoch 07 | test acc=0.8621\n",
      "Epoch 08 | test acc=0.8621\n",
      "Epoch 09 | test acc=0.8674\n",
      "Epoch 10 | test acc=0.8679\n",
      "Epoch 11 | test acc=0.8708\n",
      "Epoch 12 | test acc=0.8690\n",
      "Epoch 13 | test acc=0.8706\n",
      "Epoch 14 | test acc=0.8740\n",
      "Epoch 15 | test acc=0.8732\n",
      "Epoch 16 | test acc=0.8756\n",
      "Epoch 17 | test acc=0.8767\n",
      "Epoch 18 | test acc=0.8782\n",
      "Epoch 19 | test acc=0.8777\n",
      "Epoch 20 | test acc=0.8753\n",
      "Epoch 21 | test acc=0.8767\n",
      "Epoch 22 | test acc=0.8759\n",
      "Epoch 23 | test acc=0.8796\n",
      "Epoch 24 | test acc=0.8809\n",
      "Epoch 25 | test acc=0.8785\n",
      "Epoch 26 | test acc=0.8804\n",
      "Epoch 27 | test acc=0.8825\n",
      "Epoch 28 | test acc=0.8782\n",
      "Epoch 29 | test acc=0.8801\n",
      "Epoch 30 | test acc=0.8809\n",
      "Epoch 31 | test acc=0.8809\n",
      "Epoch 32 | test acc=0.8812\n",
      "Early stop\n",
      "MLP test accuracy: 0.8825\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism      0.886     0.925     0.905       160\n",
      "           comp.graphics      0.764     0.815     0.789       195\n",
      " comp.os.ms-windows.misc      0.817     0.772     0.794       197\n",
      "comp.sys.ibm.pc.hardware      0.730     0.786     0.757       196\n",
      "   comp.sys.mac.hardware      0.865     0.829     0.847       193\n",
      "          comp.windows.x      0.903     0.894     0.898       198\n",
      "            misc.forsale      0.819     0.882     0.849       195\n",
      "               rec.autos      0.847     0.919     0.881       198\n",
      "         rec.motorcycles      0.963     0.915     0.938       199\n",
      "      rec.sport.baseball      0.955     0.970     0.963       199\n",
      "        rec.sport.hockey      0.975     0.970     0.972       200\n",
      "               sci.crypt      0.979     0.944     0.961       198\n",
      "         sci.electronics      0.842     0.782     0.811       197\n",
      "                 sci.med      0.947     0.909     0.928       198\n",
      "               sci.space      0.910     0.924     0.917       197\n",
      "  soc.religion.christian      0.908     0.945     0.926       199\n",
      "      talk.politics.guns      0.885     0.885     0.885       182\n",
      "   talk.politics.mideast      1.000     0.936     0.967       188\n",
      "      talk.politics.misc      0.822     0.897     0.858       155\n",
      "      talk.religion.misc      0.837     0.690     0.757       126\n",
      "\n",
      "                accuracy                          0.882      3770\n",
      "               macro avg      0.883     0.879     0.880      3770\n",
      "            weighted avg      0.884     0.882     0.883      3770\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/31 14:47:14 WARNING mlflow.utils.requirements_utils: Found torch version (2.9.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.9.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/10/31 14:47:17 WARNING mlflow.utils.requirements_utils: Found torch version (2.9.0+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.9.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['comp.sys.mac.hardware', 'alt.atheism']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "mlflow.set_experiment(\"20ng-mlp-svd\") \n",
    "\n",
    "dataset = fetch_20newsgroups(subset='all')\n",
    "X, y = dataset.data, dataset.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=30000, sublinear_tf=True)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf  = tfidf.transform(X_test)\n",
    "\n",
    "svd = TruncatedSVD(n_components=200, random_state=42)\n",
    "X_train_svd = svd.fit_transform(X_train_tfidf)\n",
    "X_test_svd  = svd.transform(X_test_tfidf)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = len(np.unique(y_train))\n",
    "in_dim = X_train_svd.shape[1]\n",
    "\n",
    "Xtr = torch.tensor(X_train_svd, dtype=torch.float32)\n",
    "ytr = torch.tensor(y_train, dtype=torch.long)\n",
    "Xte = torch.tensor(X_test_svd,  dtype=torch.float32)\n",
    "yte = torch.tensor(y_test,  dtype=torch.long)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(Xtr, ytr), batch_size=256, shuffle=True)\n",
    "test_loader  = DataLoader(TensorDataset(Xte, yte), batch_size=512, shuffle=False)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = MLP(in_dim, num_classes).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "best_acc, patience, wait = 0.0, 5, 0\n",
    "\n",
    "with mlflow.start_run(run_name=\"mlp-svd-baseline\"):\n",
    "    mlflow.log_params({\n",
    "        \"tfidf_stop_words\": \"english\",\n",
    "        \"tfidf_max_features\": 30000,\n",
    "        \"tfidf_sublinear_tf\": True,\n",
    "        \"svd_n_components\": 200,\n",
    "        \"model_hidden_1\": 512,\n",
    "        \"model_hidden_2\": 256,\n",
    "        \"dropout\": 0.3,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"lr\": 1e-3,\n",
    "        \"weight_decay\": 1e-4,\n",
    "        \"batch_size\": 256,\n",
    "        \"patience\": patience,\n",
    "        \"device\": str(device),\n",
    "        \"num_classes\": int(num_classes),\n",
    "        \"input_dim\": int(in_dim),\n",
    "        \"random_state\": 42,\n",
    "        \"test_size\": 0.2,\n",
    "    })\n",
    "\n",
    "    for epoch in range(50):\n",
    "        model.train()\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            opt.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = loss_fn(logits, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = model(Xte.to(device))\n",
    "            preds = logits.argmax(dim=1)\n",
    "            acc = (preds.cpu() == yte).float().mean().item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1:02d} | test acc={acc:.4f}\")\n",
    "        mlflow.log_metric(\"test_accuracy\", acc, step=epoch+1)\n",
    "\n",
    "        if acc > best_acc + 1e-4:\n",
    "            best_acc, wait = acc, 0\n",
    "            torch.save(model.state_dict(), \"mlp_svd_best.pt\")\n",
    "            mlflow.log_metric(\"best_accuracy\", best_acc, step=epoch+1)\n",
    "            mlflow.log_artifact(\"mlp_svd_best.pt\", artifact_path=\"checkpoints\")\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                print(\"Early stop\")\n",
    "                break\n",
    "\n",
    "    try:\n",
    "        state = torch.load(\"mlp_svd_best.pt\", map_location=device, weights_only=True)\n",
    "    except TypeError:\n",
    "        state = torch.load(\"mlp_svd_best.pt\", map_location=device)\n",
    "    model.load_state_dict(state)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(Xte.to(device))\n",
    "        preds = logits.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "    final_acc = accuracy_score(y_test, preds)\n",
    "    print(f\"MLP test accuracy: {final_acc:.4f}\")\n",
    "    mlflow.log_metric(\"final_test_accuracy\", final_acc)\n",
    "\n",
    "    report_str = classification_report(y_test, preds, target_names=dataset.target_names, digits=3)\n",
    "    print(report_str)\n",
    "    with open(\"classification_report.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(report_str)\n",
    "    mlflow.log_artifact(\"classification_report.txt\", artifact_path=\"reports\")\n",
    "\n",
    "    joblib.dump(tfidf, \"tfidf_20ng.joblib\")\n",
    "    joblib.dump(svd,   \"svd_20ng_200.joblib\")\n",
    "    mlflow.log_artifact(\"tfidf_20ng.joblib\",   artifact_path=\"preprocessing\")\n",
    "    mlflow.log_artifact(\"svd_20ng_200.joblib\", artifact_path=\"preprocessing\")\n",
    "\n",
    "    mlflow.pytorch.log_model(model, artifact_path=\"model\", registered_model_name=None)\n",
    "\n",
    "def predict_texts(texts):\n",
    "    X = tfidf.transform(texts)\n",
    "    X = svd.transform(X)\n",
    "    Xt = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(Xt)\n",
    "        labels = logits.argmax(dim=1).cpu().numpy().tolist()\n",
    "    return [dataset.target_names[i] for i in labels]\n",
    "\n",
    "predict_texts([\n",
    "    \"GPU driver fails on my Mac laptop\",\n",
    "    \"Theology debate about atheism and religion\",\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e010cb",
   "metadata": {},
   "source": [
    "Metrics for the best neural network model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104aaf6e",
   "metadata": {},
   "source": [
    "![image.png](screenshots/nn_metrics.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1636f338",
   "metadata": {},
   "source": [
    "The best model chosen by PyCaret is Logistic Regression. The metrics are:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e1552a",
   "metadata": {},
   "source": [
    "![image.png](screenshots/lr_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e4fa00",
   "metadata": {},
   "source": [
    "![image.png](screenshots/lr_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45de78ea",
   "metadata": {},
   "source": [
    "Features importances:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc1334b",
   "metadata": {},
   "source": [
    "![image.png](screenshots/features_importances_lr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5c62dd",
   "metadata": {},
   "source": [
    "Confusion matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e39453",
   "metadata": {},
   "source": [
    "![Alt text](screenshots/lr_cm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cd3ee4",
   "metadata": {},
   "source": [
    "![Alt text](screenshots/cr_nn.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
